#!/bin/bash
#karoshi_gluster
#Copyright (C) 2014  Paul Sharrad
#This program is free software; you can redistribute it and/or
#modify it under the terms of the GNU General Public License
#as published by the Free Software Foundation; either version 2
#of the License, or (at your option) any later version.
#
#This program is distributed in the hope that it will be useful,
#but WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#GNU General Public License for more details.
#
#You should have received a copy of the GNU General Public License
#along with this program; if not, write to the Free Software
#Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA  02111-1307, USA.
#
#The Karoshi Team can be contacted at: 
#mpsharrad@karoshi.org.uk
#jharris@karoshi.org.uk
#
#Website: http://www.karoshi.org.uk

LOG_DATE=`date +%F`

TYPE=replica
MOUNTBASE=/mnt-gluster
GLUSTERBASE=/home/gluster-volumes
SERVERLIST=$1
VOLUME=$2
ACTION=$3
REMOTE_USER=$4
REMOTE_ADDR=$5

[ -f /opt/karoshi/web_controls/user_prefs/$REMOTE_USER ] && source /opt/karoshi/web_controls/user_prefs/$REMOTE_USER
TEXTDOMAIN=karoshi-server

#Create gluster folders
[ ! -d $GLUSTERBASE ] && mkdir -p $GLUSTERBASE
[ ! -d $MOUNTBASE ] && mkdir -p $MOUNTBASE

function usage {
echo -e "karoshi_gluster usage:\n\nkaroshi_gluster serverlist volume action\n\nserverlist - comma separated list of servers to create the gluster volume on.\n\nvolume - the name of the volume to create.\\n\naction: create/add\n\ncreate: create a new gluster volume\nadd: add a new server to an existing volume.\n\nExample 1: Create a new glusterfs volume\n\nkaroshi_gluster server1.mydomain.com,server2.mydomain.com glustervol create\n\nExample 2: An an extra server to a glusterfs volume\n\nkaroshi_gluster server3.mydomain.com glustervol add\n"
}

if [ -z "$SERVERLIST" ]
then
	usage
	exit 101
fi

if [ -z "$VOLUME" ]
then
	usage
	exit 101
fi

if [ -z "$ACTION" ]
then
	usage
	exit 101
fi

echo `date`: karoshi_gluster serverlist:$SERVERLIST volume:$VOLUME folderpath:$FOLDERPATH action:$ACTION by $REMOTE_USER from $REMOTE_ADDR >> /opt/karoshi/logs/karoshi_web_management/$LOG_DATE

source /opt/karoshi/server_network/domain_information/domain_name
PORTS=111,24007:24009,49152:49200,34865:34867

echo '<br><br><li><b>'$"Configure"' GlusterFS - '$VOLUME'</b></li><br>'

function mount_volume {
if [ "$SERVER" = `hostname-fqdn` ]
then

	#Create empty folder to mount to 
	[ ! -d "$MOUNTBASE"/"$VOLUME" ] && mkdir -p "$MOUNTBASE"/"$VOLUME"


	#Add entry to fstab
	if [ `grep -c ^#glusterfs-$VOLUME /etc/fstab` = 0 ]
	then
		echo "#glusterfs-$VOLUME" >> /etc/fstab
		echo "$SERVER:/$VOLUME $MOUNTBASE/$VOLUME glusterfs defaults,acl,_netdev 0 0" >> /etc/fstab
	fi

	#Mount volume
	echo '<li>'$SERVER' - '$"mounting"' '$MOUNTBASE/$VOLUME'</li><br>'
	mount -a
	#Create mount command
	echo -e '#!/bin/bash
	#Check if glusterfs is needed
	if [ `grep -c gluster /etc/fstab` -gt 0 ]
	then
		#Wait for glusterfs to start
		source /opt/karoshi/serversetup/variables/distro
		STATUS=1
		COUNTER=0
		while [ $STATUS = 1 ] && [ $COUNTER != 120 ]
		do
			/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_status
			STATUS=$?
			sleep 1

			if [ $STATUS = 0 ]
			then
				#Make sure gluster mount folders exists
				for glustervol in `grep -w glusterfs /etc/fstab | grep -v glusterfs- | sed "s/ /,/g"`
				do
					glustermount=`echo $glustervol | cut -d, -f2`
					#Make sure that the folder exists
					[ ! -d "$glustermount" ] && mkdir -p "$glustermount"
				done
				#Hopefully gluster is now started so mount the gluster shares
				mount -a
			exit
			fi

			let COUNTER=$COUNTER+1
		done
	fi
	exit' > /etc/rc2.d/S99mount_gluster_shares
	chmod 0755 /etc/rc2.d/S99mount_gluster_shares

else
	ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $SERVER '

	#Create empty folder to mount to 
	[ ! -d "'$MOUNTBASE'"/"'$VOLUME'" ] && mkdir -p "'$MOUNTBASE'"/"'$VOLUME'"

	#Add entry to fstab
	if [ `grep -c ^#glusterfs-'$VOLUME' /etc/fstab` = 0 ]
	then
		echo "#glusterfs-'$VOLUME'" >> /etc/fstab
		echo "'$SERVER':/'$VOLUME' '$MOUNTBASE'/'$VOLUME' glusterfs defaults,acl,_netdev 0 0" >> /etc/fstab
	fi

	#Mount volume
	echo "<li>'$SERVER' - '$"mounting"' '$MOUNTBASE'/'$VOLUME'</li><br>"
	mount -a

	#Create mount command
	echo -e "#!/bin/bash
	#Check if glusterfs is needed
	if [ \`grep -c gluster /etc/fstab\` -gt 0 ]
	then
		#Wait for glusterfs to start
		source /opt/karoshi/serversetup/variables/distro
		STATUS=1
		COUNTER=0
		while [ \$STATUS = 1 ] && [ \$COUNTER != 120 ]
		do
			/opt/karoshi/serversetup/distro/\$DISTROCHOICE/scripts/control_services/glusterfs_status
			STATUS=$?
			sleep 1

			if [ \$STATUS = 0 ]
			then
				#Make sure gluster mount folders exists
				for glustervol in \`grep -w glusterfs /etc/fstab | grep -v glusterfs- | sed \"s/ /,/g\"\`
				do
					glustermount=\`echo \$glustervol | cut -d, -f2\`
					#Make sure that the folder exists
					[ ! -d \"\$glustermount\" ] && mkdir -p \"\$glustermount\"
				done

				#Hopefully gluster is now started so mount the gluster shares
				mount -a
				exit
			fi

			let COUNTER=\$COUNTER+1
		done
	fi
	exit" > /etc/rc2.d/S99mount_gluster_shares
	chmod 0755 /etc/rc2.d/S99mount_gluster_shares
	'
fi
}

#Open ports on firewall and make sure that glusterfs is running.
function openshorewall {
if [ $SERVER = `hostname-fqdn` ]
then
	source /opt/karoshi/serversetup/variables/distro
	if [ `grep -c "karoshi_gluster" /etc/shorewall/rules` = 0 ]
	then
		echo '<li>'$SERVER' - '$"Opening ports for glusterfs"'</li><br>'

		LINENUM=`grep -n 'LAST LINE -- ADD YOUR ENTRIES BEFORE THIS ONE -- DO NOT REMOVE' /etc/shorewall/rules | cut -d: -f1`
		sed -i $LINENUM'c'\ACCEPT'	'net'	'fw'	'tcp'	'$PORTS'	'-'#'karoshi_gluster /etc/shorewall/rules
		echo ACCEPT'	'net'	'fw'	'udp'	'$PORTS'	'-'#'karoshi_gluster >> /etc/shorewall/rules
		echo '#'LAST LINE -- ADD YOUR ENTRIES BEFORE THIS ONE -- DO NOT REMOVE >> /etc/shorewall/rules

		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/shorewall_stop 1>/dev/null
		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/shorewall_start 1>/dev/null
	fi

	#Make sure glusterfs is running
	/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/startonboot/glusterfs
	/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_status
	if [ $? != 0 ]
	then
		echo '<li>'$HOSTNAME'.'$REALM' - '$"starting glusterfs"'</li><br>'
		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_start 1>/dev/null
	fi
else
	ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $SERVER '
	source /opt/karoshi/serversetup/variables/distro

	#Open ports on firewall
	if [ `grep -c "karoshi_gluster" /etc/shorewall/rules` = 0 ]
	then
		echo "<li>'$SERVER' - '$"Opening ports for glusterfs"'</li><br>"

		LINENUM=`grep -n "LAST LINE -- ADD YOUR ENTRIES BEFORE THIS ONE -- DO NOT REMOVE" /etc/shorewall/rules | cut -d: -f1`
		sed -i $LINENUM"c"\ACCEPT"	"net"	"fw"	"tcp"	"'$PORTS'"	"-"#"karoshi_gluster /etc/shorewall/rules
		echo ACCEPT"	"net"	"fw"	"udp"	"'$PORTS'"	"-"#"karoshi_gluster >> /etc/shorewall/rules
		echo "#"LAST LINE -- ADD YOUR ENTRIES BEFORE THIS ONE -- DO NOT REMOVE >> /etc/shorewall/rules

		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/shorewall_stop 1>/dev/null
		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/shorewall_start 1>/dev/null
	fi

	#Make sure glusterfs is running
	/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/startonboot/glusterfs
	/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_status
	if [ $? != 0 ]
	then
		echo "<li>'$SERVER' - '$"starting glusterfs"'</li><br>"
		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_start
	fi
'
fi
}

function detach_peer {
#Detach a peer


for PEERSERVER in `echo $SERVERLIST | sed 's/,/ /g'`
do
	if [ $SERVER != $PEERSERVER ]
	then
		if [ $PEERSERVER = `hostname-fqdn` ]
		then
			echo '<li>'$PEERSERVER' - '$"Detaching"' '$SERVER'</li><br>'
			gluster peer detach $SERVER
		else
		ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $PEERSERVER '
			echo "<li>'$PEERSERVER' - '$"Detaching"' '$SERVER'</li><br>"
			gluster peer detach '$SERVER'
		'
		fi
	fi
done
}

function add_to_pool {

#Add servers to pool
for NEWSERVER in `echo $SERVERLIST | sed 's/,/ /g'`
do
	MAINSERVER=`hostname-fqdn`
	if [ $NEWSERVER != "$MAINSERVER" ]
	then
		echo `date`: "karoshi_gluster peer probe $MAINSERVER - $NEWSERVER" >> /opt/karoshi/logs/karoshi_web_management/$LOG_DATE
		gluster peer probe "$NEWSERVER"
		echo "<br><br>"
		#Make sure that peer probe is successful
		PCOUNTER=1
		sleep 1
		while  [ `gluster peer status | grep -c $NEWSERVER` = 0 ]
		do
			sleep 1
			let PCOUNTER=$PCOUNTER+1
			if [ $PCOUNTER = 20 ]
			then
				echo "<li>"$MAINSERVER - $NEWSERVER $"Gluster peer probe failure""</li>"
				echo `date`: "karoshi_gluster peer probe failure for $MAINSERVER - $NEWSERVER" >> /opt/karoshi/logs/karoshi_web_management/$LOG_DATE
				sleep 5
				exit 101
			fi
		done
		echo `date`: "karoshi_gluster peer probe $NEWSERVER - $MAINSERVER" >> /opt/karoshi/logs/karoshi_web_management/$LOG_DATE
		ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $NEWSERVER '
		gluster peer probe '"$MAINSERVER"'
		echo "<br><br>"
		#Make sure that peer probe is successfull
		PCOUNTER=1
		sleep 1
		while  [ `gluster peer status | grep -c '$MAINSERVER'` = 0 ]
		do
			sleep 1
			let PCOUNTER=$PCOUNTER+1
			[ $PCOUNTER = 20 ] && exit 101
		done
		'	
		if [ $? = 101 ]
		then
			echo "<li>"$NEWSERVER - $MAINSERVER $"Gluster peer probe failure""</li>"
			echo `date`: "karoshi_gluster peer probe failure for $NEWSERVER - $MAINSERVER" >> /opt/karoshi/logs/karoshi_web_management/'$LOG_DATE'
			sleep 5
			exit 101
		fi

		#Check that the server is appearing as a peer in all servers in the pool
		if [ -d /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers/ ]
		then
			for CURRENTSERVER in `ls -1 /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers`
			do
				if [ $CURRENTSERVER = `hostname-fqdn` ]
				then
					PCOUNTER=1
					while  [ `gluster peer status | grep -c $NEWSERVER` = 0 ]
					do
						sleep 1
						let PCOUNTER=$PCOUNTER+1
						if [ $PCOUNTER = 30 ]
						then
							echo "<li>"$CURRENTSERVER - $NEWSERVER $"Gluster peer probe failure""</li>"
							echo `date`: "karoshi_gluster peer probe failure for $CURRENTSERVER - $NEWSERVER" >> /opt/karoshi/logs/karoshi_web_management/$LOG_DATE
							sleep 5
							exit 101
					fi
					done
				else


					ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $CURRENTSERVER '
					#Make sure that peer probe is successfull
					PCOUNTER=1
					sleep 1
					while  [ `gluster peer status | grep -c '$NEWSERVER'` = 0 ]
					do
						sleep 1
						let PCOUNTER=$PCOUNTER+1
						[ $PCOUNTER = 30 ] && exit 101
					done
					'	
					if [ $? = 101 ]
					then
						echo "<li>"$CURRENTSERVER - $NEWSERVER $"Gluster peer probe failure""</li>"
						echo `date`: "karoshi_gluster peer probe failure for $CURRENTSERVER - $MAINSERVER" >> /opt/karoshi/logs/karoshi_web_management/'$LOG_DATE'
						sleep 5
						exit 101
					fi	
				fi
			done
		fi
	fi
done
}

if [ $ACTION = create ]
then
	FIRSTSERVER=`echo $SERVERLIST | cut -d, -f1`
	COUNTER=0
	for SERVERS in `echo $SERVERLIST | sed 's/,/ /g'`
	do
		SERVER=`basename $SERVERS`
		GLUSTERCLUSTER=`echo $GLUSTERCLUSTER $SERVER:$GLUSTERBASE/$VOLUME`
		#Open shorewall ports and make sure that glusterfs is running
		openshorewall
		if [ "$SERVER" = `hostname-fqdn` ]
		then
			#Create gluster folders
			[ ! -d "$GLUSTERBASE" ] && mkdir -p "$GLUSTERBASE"
			[ ! -d "$MOUNTBASE" ] && mkdir -p "$MOUNTBASE"

			#Delete brick folder if it exists
			[ -d "$GLUSTERBASE"/"$VOLUME" ] && rm -f -R "$GLUSTERBASE"/"$VOLUME"
		else
			ssh -o PasswordAuthentication=no -o ConnectTimeout=3 "$SERVER" '

			#Create gluster folders
			[ ! -d "'$GLUSTERBASE'" ] && mkdir -p "'$GLUSTERBASE'"
			[ ! -d "'$MOUNTBASE'" ] && mkdir -p "'$MOUNTBASE'"

			#Delete brick folder if it exists
			[ -d "'$GLUSTERBASE'"/"'$VOLUME'" ] && rm -f -R '$GLUSTERBASE'/'$VOLUME'
			'
		fi

		let COUNTER=$COUNTER+1
	done

	#Add all listed servers to the pool
	add_to_pool

	if [ "$FIRSTSERVER" = `hostname-fqdn` ]
	then
		#Create glusterfs volume
		echo '<li>'$FIRSTSERVER' - '$"Creating GlusterFS volume"' - '$VOLUME'</li><br>'
		gluster volume create $VOLUME $TYPE $COUNTER $GLUSTERCLUSTER force 1>/dev/null 
		if [ $? != 0 ]
		then
			echo '<li>'$"There was a problem creating the volume"' - '$VOLUME'</li><br>'
			sleep 3
			exit 101
		fi
		#Start Gluster volume
		echo '<li>'$"Starting GlusterFS volume"' - '$VOLUME'</li><br>'
		gluster volume start $VOLUME 1>/dev/null
		if [ $? != 0 ]
		then
			echo '<li>'$"There was a problem starting the volume"' - '$VOLUME'</li><br>'
			sleep 3
			exit 101
		fi
	else
		ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $FIRSTSERVER '
		#Create glusterfs volume
		echo "<li>'$FIRSTSERVER' - '$"Creating GlusterFS volume"' - '$VOLUME'</li><br>"
		gluster volume create '$VOLUME' '$TYPE' '$COUNTER' '$GLUSTERCLUSTER' force 1>/dev/null 
		if [ $? != 0 ]
		then
			echo "<li>'$"There was a problem creating the volume"' - '$VOLUME'</li><br>"
			sleep 3
			exit 101
		fi
		#Start Gluster volume
		echo "<li>'$"Starting GlusterFS volume"' - '$VOLUME'</li><br>"
		gluster volume start '$VOLUME' 1>/dev/null
		if [ $? != 0 ]
		then
			echo "<li>'$"There was a problem starting the volume"' - '$VOLUME'</li><br>"
			sleep 3
			exit 101
		fi
		'
		[ $? = 101 ] && exit 101
	fi

	for SERVERS in `echo $SERVERLIST | sed 's/,/ /g'`
	do
		SERVER=`basename $SERVERS`
		mount_volume
		echo GlusterFS Server"<br>" > /opt/karoshi/server_network/servers/$SERVER/glusterfs_server
	done

	#Restrict access to the gluster volume
	gluster volume set $VOLUME auth.allow 127.0.0.1

	#Add in flag files for volume creation
	[ ! -d /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers ] && mkdir -p /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers
	[ ! -d /opt/karoshi/server_network/gluster-volumes/$VOLUME/folders ] && mkdir -p /opt/karoshi/server_network/gluster-volumes/$VOLUME/folders
	for SERVER in `echo $SERVERLIST | sed 's/,/ /g'`
	do
		touch /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers/$SERVER
		echo $"GlusterFS Server""<br>" > /opt/karoshi/server_network/servers/$SERVER/glusterfs_server
	done
fi

###########################
#Add an extra server to an existing gluster volume
###########################

if [ $ACTION = add ]
then
	SERVER=$SERVERLIST
	echo '<li>'$SERVER' - '$"Adding server to gluster volume"' - '$VOLUME'</li><br>'

	#Open shorewall ports and make sure that glusterfs is running
	openshorewall

	#Create gluster folders
	if [ $SERVER = `hostname-fqdn` ]
	then
		#Create gluster folders
		[ ! -d $GLUSTERBASE ] && mkdir -p $GLUSTERBASE
		[ ! -d $MOUNTBASE ] && mkdir -p $MOUNTBASE

		#Delete brick folder if it exists
		[ -d $GLUSTERBASE/$VOLUME ] && rm -f -R $GLUSTERBASE/$VOLUME
	else
		ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $SERVER '

		#Create gluster folders
		[ ! -d "'$GLUSTERBASE'" ] && mkdir -p "'$GLUSTERBASE'"
		[ ! -d "'$MOUNTBASE'" ] && mkdir -p "'$MOUNTBASE'"

		#Delete brick folder if it exists
		[ -d "'$GLUSTERBASE'"/"'$VOLUME'" ] && rm -f -R "'$GLUSTERBASE'"/"'$VOLUME'"
		'
	fi

	#Add all listed servers to the pool
	add_to_pool

	#Get current number of bricks in the volume
	BRICKCOUNT=`ls -1 /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers/ | wc -l`
	let BRICKCOUNT=$BRICKCOUNT+1

	#Add gluster brick to volume
	gluster volume add-brick $VOLUME replica $BRICKCOUNT $SERVER:$GLUSTERBASE/$VOLUME force
	echo "<br><br>"

	#Mount the drive
	mount_volume

	#Add in gluster information
	echo GlusterFS Server"<br>" > /opt/karoshi/server_network/servers/$SERVER/glusterfs_server
	touch /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers/$SERVER
fi

#Restore a server to an existing gluster volume.
if [ $ACTION = restore ]
then
	SERVER=$SERVERLIST

	#Dont restore if the volume if it is mounted and running on the server
	if [ $SERVER = `hostname-fqdn` ]
	then
		if [ `mount | grep -c -w $VOLUME` -gt 0 ]
		then
			exit
		fi
	else
		ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $SERVER '
		if [ `mount | grep -c -w '$VOLUME'` -gt 0 ]
		then
			exit 1
		else
			exit 0
		fi		
		'
	fi
	if [ $? != 0 ]
	then
		echo `date`: "karoshi_gluster volume is mounted on $SERVER." >> /opt/karoshi/logs/karoshi_web_management/$LOG_DATE
		exit
	fi

	echo '<li>'$SERVER' - '$"Restoring"' '$VOLUME'</li>'
	#Get list of servers in the gluster volume
	SERVERLIST=`ls -1 /opt/karoshi/server_network/gluster-volumes/$VOLUME/servers/`
	#Open shorewall ports and make sure that glusterfs is running
	openshorewall
	sleep 2
	detach_peer
	sleep 2
	add_to_pool

	if [ $SERVER = `hostname-fqdn` ]
	then
			#Create folder for gluster volume
			[ ! -d $GLUSTERBASE ] && mkdir -p $GLUSTERBASE/$VOLUME
			[ ! -d $MOUNTBASE ] && mkdir -p $MOUNTBASE
			echo '<li>'$HOSTNAME'.'$REALM' - '$"stopping glusterfs"'</li><br>'
			/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_stop 1>/dev/null
			sleep 1
			echo '<li>'$HOSTNAME'.'$REALM' - '$"Starting glusterfs"'</li><br>'
			/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_start 1>/dev/null
			#Wait for volinfo to appear
			VCOUNTER=1
			sleep 1
			while  [ ! -f /var/lib/glusterd/vols/$VOLUME/info ]
			do
				sleep 1
				let VCOUNTER=$VCOUNTER+1
				if [ $VCOUNTER = 30 ]
				then
					echo "<li>"$SERVER - "$No volume information""</li>"
					exit 101
				fi
			done
			(vol=$VOLUME; brick=$GLUSTERBASE/$VOLUME; setfattr -n  trusted.glusterfs.volume-id -v 0x$(grep volume-id /var/lib/glusterd/vols/$vol/info | cut -d= -f2 | sed "s/-//g") $brick)
			gluster volume start $VOLUME force
			sleep 5
			gluster volume heal $VOLUME full
	else
		ssh -o PasswordAuthentication=no -o ConnectTimeout=3 $SERVER '
			source /opt/karoshi/serversetup/variables/distro
			#Create folder for gluster volume
			[ ! -d "'$GLUSTERBASE'"/"'$VOLUME'" ] && mkdir -p "'$GLUSTERBASE'"/"'$VOLUME'"
			[ ! -d "'$MOUNTBASE'" ] && mkdir -p "'$MOUNTBASE'"

			echo "<li>"$HOSTNAME.'$REALM' - '$"stopping glusterfs"'"</li><br>"
			/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_stop 1>/dev/null
			sleep 1
			echo "<li>"$HOSTNAME.'$REALM' - '$"Starting glusterfs"'"</li><br>"
			/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/glusterfs_start 1>/dev/null
			#Wait for volinfo to appear
			VCOUNTER=1
			sleep 1
			while  [ ! -f /var/lib/glusterd/vols/'$VOLUME'/info ]
			do
				sleep 1
				let VCOUNTER=$VCOUNTER+1
				if [ $VCOUNTER = 30 ]
				then
					echo "<li>"'$SERVER' - '$"No volume information"'"</li>"
					exit 101
				fi
			done
			(vol='$VOLUME'; brick='$GLUSTERBASE'/'$VOLUME'; setfattr -n  trusted.glusterfs.volume-id -v 0x$(grep volume-id /var/lib/glusterd/vols/$vol/info | cut -d= -f2 | sed "s/-//g") $brick)
			gluster volume start '$VOLUME' force
			sleep 5
			gluster volume heal '$VOLUME' full
		'
	fi
	mount_volume
fi

exit

