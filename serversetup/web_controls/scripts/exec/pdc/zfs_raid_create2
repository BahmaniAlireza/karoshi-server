#!/bin/bash
#Copyright (C) 2010 Paul Sharrad

#This file is part of Karoshi Server.
#
#Karoshi Server is free software: you can redistribute it and/or modify
#it under the terms of the GNU Affero General Public License as published by
#the Free Software Foundation, either version 3 of the License, or
#(at your option) any later version.
#
#Karoshi Server is distributed in the hope that it will be useful,
#but WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#GNU Affero General Public License for more details.
#
#You should have received a copy of the GNU Affero General Public License
#along with Karoshi Server.  If not, see <http://www.gnu.org/licenses/>.

#
#The Karoshi Team can be contacted at: 
#mpsharrad@karoshi.org.uk
#jsharrad@karoshi.org.uk

#
#Website: http://www.karoshi.org.uk
LOG_DATE=$(date +%F)
########################
#Check md5checksum
########################
if ! test -f /opt/karoshi/web_controls/checksums/admin_checksums/zfs_raid_create2_cgi
then
	echo "$(date): zfs_raid_create2 - No admin Checksum" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi
source /opt/karoshi/web_controls/checksums/admin_checksums/zfs_raid_create2_cgi
Checksum=$(sha256sum /var/www/cgi-bin_karoshi/admin/zfs_raid_create2.cgi | cut -d' ' -f1)
[ -z "$Checksum" ] && Checksum=not_set
if [ "$Checksum"'check' != "$zfs_raid_create2_cgi"'check' ]
then
	echo "$(date): zfs_raid_create2 - Incorrect admin Checksum" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi

########################
#Get variables
########################
numArgs="$#"
if [ "$numArgs" != 0 ]
then
	echo "$(date): zfs_raid_create2 - incorrect number of arguments" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi

read DATA
DATA=$(echo "$DATA" | tr -cd 'A-Za-z0-9:._,/-')
if [ -z "$DATA" ]
then
	echo "$(date): zfs_raid_create2 - no data" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi
REMOTE_USER=$(echo "$DATA" | cut -s -d: -f1)
REMOTE_ADDR=$(echo "$DATA" | cut -s -d: -f2)
RemoteCheckSum=$(echo "$DATA" | cut -s -d: -f3)
SERVERNAME=$(echo "$DATA" | cut -s -d: -f4)
SERVERTYPE=$(echo "$DATA" | cut -s -d: -f5)
SERVERMASTER=$(echo "$DATA" | cut -s -d: -f6)
ACTION=$(echo "$DATA" | cut -s -d: -f7)
PARITY=$(echo "$DATA" | cut -s -d: -f8)
DRIVELIST=$(echo "$DATA" | cut -s -d: -f9)
SPAREDRIVELIST=$(echo "$DATA" | cut -s -d: -f10)
MOUNTPOINT=$(echo "$DATA" | cut -s -d: -f11)
CREATETYPE=$(echo "$DATA" | cut -s -d: -f12)

ZPOOLTOPPATH=dev/zvol

########################
#Check data
########################
if [ "$RemoteCheckSum"'check' != "$Checksum"'check' ]
then
	echo "$(date): zfs_raid_create2 - Not called by zfs_raid_create2.cgi" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi
if [ -z "$REMOTE_USER" ]
then
	echo "$(date): zfs_raid_create2 - Blank remote user" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi
if [ -z "$REMOTE_ADDR" ]
then
	echo "$(date): zfs_raid_create2 - Blank remote tcpip address" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi
if [ -z "$SERVERNAME" ]
then
	echo "$(date): zfs_raid_create2 - Blank server" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi
if [ -z "$SERVERTYPE" ]
then
	echo "$(date): zfs_raid_create2 - Blank servertype" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi
if [ "$SERVERTYPE" = federatedslave ]
then
	if [ -z "$SERVERMASTER" ]
	then
		echo "$(date): zfs_raid_create2 - Blank servermaster" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
		exit 101
	fi
fi

if [ -z "$CREATETYPE" ]
then
	echo "$(date): zfs_raid_create2 - Blank createtype" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi

if [ "$CREATETYPE" != restore ] && [ "$CREATETYPE" != create ] && [ "$CREATETYPE" != reuse ]
then
	echo "$(date): zfs_raid_create2 - incorrect createtype" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi

if [ "$CREATETYPE" = create ]
then
	if [ -z "$PARITY" ]
	then
		echo "$(date): zfs_raid_create2 - Blank parity" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
		exit 101
	fi

	if [ -z "$DRIVELIST" ]
	then
		echo "$(date): zfs_raid_create2 - Blank drives" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
		exit 101
	fi

	if [ -z "$MOUNTPOINT" ]
	then
		echo "$(date): zfs_raid_create2 - Blank mountpoint" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
		exit 101
	fi
fi

if [[ $(grep -c ^"$REMOTE_USER:" /opt/karoshi/web_controls/web_access_admin) != 1 ]]
then
	echo "$(date): zfs_raid_create2 - access denied to $REMOTE_USER from $REMOTE_ADDR" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"
	exit 101
fi


[ "$CREATETYPE" = create ] && echo "$(date): zfs_raid_create2 - servername $SERVERNAME servertype $SERVERTYPE parity $PARITY drivelist $DRIVELIST $SPAREDRIVELIST mountpoint $MOUNTPOINT by $REMOTE_USER from $REMOTE_ADDR" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"

[ "$CREATETYPE" = restore ] && echo "$(date): zfs_raid_create2 - restoring zfs raid by $REMOTE_USER from $REMOTE_ADDR" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"

[ "$CREATETYPE" = reuse ] && echo "$(date): zfs_raid_create2 - reusing drives for a new zfs raid by $REMOTE_USER from $REMOTE_ADDR" >> "/opt/karoshi/logs/karoshi_web_management/$LOG_DATE"


##########################
#Language
##########################

[ -f /opt/karoshi/web_controls/user_prefs/"$REMOTE_USER" ] && source /opt/karoshi/web_controls/user_prefs/"$REMOTE_USER"
export TEXTDOMAIN=karoshi-server

source /opt/karoshi/serversetup/variables/distro

POOLNAME=$(echo zfs"$MOUNTPOINT" | sed 's/\//-/g')

if [[ "$SERVERNAME" = $(hostname-fqdn) ]]
then
	#Make sure zfs kernel module is loaded
	modprobe zfs
	#Make sure zfs is going to load on boot and load created pools
	echo "zfs zfs_autoimport_disable=0" > /etc/modules-load.d/zfs.conf
	#Add cron job for zpool scrub
	[ -d /opt/karoshi/server_network/cronjobs/"$SERVERNAME"/jobs ] || mkdir -p /opt/karoshi/server_network/cronjobs/"$SERVERNAME"/jobs
	echo 0 0 '*' '*' 6 zpool scrub "$POOLNAME" > /opt/karoshi/server_network/cronjobs/"$SERVERNAME/jobs/zpool_scrub_$POOLNAME.cron"
	/opt/karoshi/serversetup/all/"useful scripts"/refreshcronjobs
	echo "<br>"

	SORTGLUSTER=no
	if [ -d /home/gluster-volumes/ ] && [ "$MOUNTPOINT" = /home ]
	then
		SORTGLUSTER=yes
	fi

	function sort_gluster {
	source /opt/karoshi/serversetup/variables/distro
	if [ "$GLUSTERACTION" = stop ]
	then
		echo '<ul><li>'$"Stopping Samba4"'</li></ul>'
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/control_services/samba_stop 1>/dev/null
		echo '<ul><li>'$"Stopping GlusterFS"'</li></ul>'
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/control_services/glusterfs_stop 1>/dev/null
	fi
	if [ "$GLUSTERACTION" = start ]
	then
		echo '<ul><li>'$"Starting GlusterFS"'</li></ul>'
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/control_services/glusterfs_start 1>/dev/null
	fi
	for GLUSTERVOL in $(ls /home/gluster-volumes/)
	do
		if [ "$GLUSTERACTION" = stop ]
		then
			#Clear out all of the gluster data
			echo '<ul><li>'$"Glusterfs"' - '$"Removing"' '"$GLUSTERVOL"' - '$"This will be restored after the ZFS array has been created"'</li></ul>'
			umount /mnt-gluster/"$GLUSTERVOL"
			rm -f -R /home/gluster-volumes/"$GLUSTERVOL"
			mkdir -p /home/gluster-volumes/"$GLUSTERVOL"
		fi		


		if [ "$GLUSTERACTION" = start ]
		then
			#Create new volume id otherwise the gluster volume will not start.
			(vol="$GLUSTERVOL"; brick=/home/gluster-volumes/"$GLUSTERVOL"; setfattr -n  trusted.glusterfs.volume-id -v 0x$(grep volume-id /var/lib/glusterd/vols/$vol/info | cut -d= -f2 | sed 's/-//g') "$brick")
			#Restart the gluster volume
			echo -e "y\n" | gluster volume stop "$GLUSTERVOL" force
			sleep 1
			gluster volume start "$GLUSTERVOL" force
			#Repair the volume with data from the other server.
			gluster volume heal "$GLUSTERVOL" full
			mount -a
		fi			
	done
	if [ "$GLUSTERACTION" = start ]
	then
		#Mount gluster volume and start samba4
		mount -a
		echo '<ul><li>'$"Starting Samba4"'</li></ul>'
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/control_services/samba_start 1>/dev/null
	fi
	}

	if [ "$CREATETYPE" = create ]
	then
		DRIVELIST=$(echo "$DRIVELIST" | sed "s/,/ /g")
		#Create the zfs raid
		echo '<pre style="font-size: 10pt; font-family:Arial, Times, Georgia, serif">'

		

		if [ "$PARITY" = stripe ]
		then
			echo '<ul><li>'$"Creating ZFS stripe"'</li></ul>'
		elif [ "$PARITY" = mirror ]
		then
			echo '<ul><li>'$"Creating ZFS mirror"'</li></ul>'
		else		
			echo '<ul><li>'$"Creating ZFS raid"' z'"$PARITY"'</li></ul>'
		fi
		#Check that there is not already a pool created for this zfs raid
		if [[ $(zpool status | grep -c -w "$POOLNAME") -gt 0 ]]
		then
			echo "$POOLNAME" - $"A ZFS raid has already been set up for this pool.""<br>"
			sleep 3
			exit 101
		fi

		if [ "$PARITY" = stripe ]
		then
			zpool create -o ashift=12 -f "$POOLNAME" $DRIVELIST
		elif [ "$PARITY" = mirror ]
		then
			#Create a zfs mirror
			if [ ! -z "$SPAREDRIVELIST" ]
			then
				SPAREDRIVELIST=$(echo "$SPAREDRIVELIST" | sed "s/,/ /g")
				zpool create -o ashift=12 -f "$POOLNAME" mirror $DRIVELIST spare $SPAREDRIVELIST
			else
				zpool create -o ashift=12 -f "$POOLNAME" mirror $DRIVELIST
			fi
		else
			#Create a raidz volume
			if [ ! -z "$SPAREDRIVELIST" ]
			then
				SPAREDRIVELIST=$(echo "$SPAREDRIVELIST" | sed "s/,/ /g")
				zpool create -o ashift=12 -f "$POOLNAME" raidz"$PARITY" $DRIVELIST spare $SPAREDRIVELIST
			else
				zpool create -o ashift=12 -f "$POOLNAME" raidz"$PARITY" $DRIVELIST
			fi
			
		fi
		#Check zfs raid has been created
		zpool status "$POOLNAME"
		if [ "$?" != 0 ]
		then
			echo $"A ZFS raid has not been set up on this server.""<br>"
			sleep 3
			exit 101
		fi

		#Set posix acl support
		zfs set acltype=posixacl "$POOLNAME"

		#Disable dedup as it needs a lot of memory 
		zfs set dedup=off "$POOLNAME"
		
		#Mount partition on a temporary mount point
		[ ! -d "$MOUNTPOINT.$$" ] && mkdir -p "$MOUNTPOINT.$$"

		zfs set mountpoint="$MOUNTPOINT.$$" "$POOLNAME"
		zfs mount "$POOLNAME"

		#Stop services if the mount point is /var
		if [[ $(echo "$MOUNTPOINT" | grep -c /var) -gt 0 ]]
		then
			source /opt/karoshi/serversetup/variables/distro

			SERVICEARRAY=( apache dansguardian mysql samba squid )
			SERVICEARRAYCOUNT="${#SERVICEARRAY[@]}"

			#Stop services if they are running
			COUNTER=0
			while [ "$COUNTER" -lt "$SERVICEARRAYCOUNT" ]
			do
				#Check if the service is running
				/opt/karoshi/serversetup/distro/ubuntu/scripts/control_services/"${SERVICEARRAY[$COUNTER]}"_status
				STATUSARRAY[$COUNTER]="$?"
				#Stop service if it is running
				if [ "${STATUSARRAY[$COUNTER]}" = 0 ]
				then
					echo '<ul><li>'"${SERVICEARRAY[$COUNTER]}"' - '$"Stopping this service."'</li></ul>'
					/opt/karoshi/serversetup/distro/ubuntu/scripts/control_services/"${SERVICEARRAY[$COUNTER]}"_stop
				fi
				let COUNTER=$COUNTER+1
			done 
		fi

		#Copy data to new array
		if [ -d "$MOUNTPOINT" ]
		then
			if [ "$SORTGLUSTER" = yes ]
			then
				GLUSTERACTION=stop
				sort_gluster
			fi
			echo '<ul><li>'$"Copying existing data onto the raid."'</b></li></ul>'
			sleep 2
			rsync --timeout=30 --verbose --dirs --recursive --links --compress --times --perms --acls --executability --owner --group -o "$MOUNTPOINT/ $MOUNTPOINT.$$/"
			
			#Move existing folder and create a new empty folder
			mv "$MOUNTPOINT" "$MOUNTPOINT-pre-zfs.$$"
			mkdir "$MOUNTPOINT"
		fi

		#Remove any existing partitions from fstab
		if [[ $(grep -c -w "$MOUNTPOINT" /etc/fstab) -gt 0 ]]
		then
			#Umount the partition
			echo '<ul><li>'"$MOUNTPOINT"'- '$"Un mounting existing partition"'</li></ul>'
			umount "$MOUNTPOINT"

			#Backup /etc/fstab
			echo "<ul><li>"Backing up fstab"</li></ul>"
			cp /etc/fstab /etc/fstab-backup.$$

			#Remove entry from fstab
			sed -i '\%'"$MOUNTPOINT"'%d' /etc/fstab
		fi

		#Unmount zfs partition and mount as /home
		umount "$MOUNTPOINT.$$"
		zfs set mountpoint="$MOUNTPOINT" "$POOLNAME"
		zfs mount "$POOLNAME"

		#Remove temporary mount point
		[ -d "$MOUNTPOINT.$$" ] && rm -f -R "$MOUNTPOINT.$$"

		if [ "$SORTGLUSTER" = yes ]
		then
			GLUSTERACTION=start
			sort_gluster
		fi

		echo "</pre>"

		#Mount partition on boot
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/startonboot/zfs-mount-all

		#Start services if they were previously running and were stopped to create a raid on /var
		if [[ $(echo "$MOUNTPOINT" | grep -c /var) -gt 0 ]]
		then
			COUNTER=0
			while [ "$COUNTER" -lt "$SERVICEARRAYCOUNT" ]
			do
				if [ "${STATUSARRAY[$COUNTER]}" = 0 ]
				then
					echo '<ul><li>'"${SERVICEARRAY[$COUNTER]}"' - '$"Starting this service."'</li></ul>'
					/opt/karoshi/serversetup/distro/ubuntu/scripts/control_services/"${SERVICEARRAY[$COUNTER]}"_start
				fi
				let COUNTER="$COUNTER"+1
			done
		fi
	fi

	#Restore existing zfs raid
	if [ "$CREATETYPE" = restore ]
	then
		if [ "$SORTGLUSTER" = yes ]
		then
			GLUSTERACTION=stop
			sort_gluster
		fi

		if [ -d "$MOUNTPOINT" ]
		then
			mv "$MOUNTPOINT" "$MOUNTPOINT"-pre-zfs.$$
		fi
		mkdir -p "$MOUNTPOINT"

		zpool import -f -d /dev/disk/by-id "$POOLNAME"

		#Set posix acl support
		zfs set acltype=posixacl "$POOLNAME"

		#Disable dedup as it needs a lot of memory
		zfs set dedup=off "$POOLNAME"

		zfs set mountpoint="$MOUNTPOINT" "$POOLNAME"
		zfs mount "$POOLNAME"

		#Copy any existing data back onto the raid
		if [ -d "$MOUNTPOINT"-pre-zfs.$$ ]
		then
			echo "<pre style=\"font-size: 10pt; font-family:Arial, Times, Georgia, serif\">"
			rsync --timeout=30 --verbose --dirs --recursive --links --compress --times --perms --acls --executability --owner --group -o "$MOUNTPOINT-pre-zfs.$$"/ "$MOUNTPOINT"/
			echo "</pre>"
		fi

		if [ "$SORTGLUSTER" = yes ]
		then
			GLUSTERACTION=start
			sort_gluster
		fi

		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/startonboot/zfs-mount-all
	fi

	#Reuse existing zfs raid
	if [ "$CREATETYPE" = reuse ]
	then
		echo "</form><form METHOD=POST ACTION=\"/cgi-bin/admin/zfs_raid_create.cgi\" target=\"_top\" name = \"frm\">
<input type=\"hidden\" name=\"____SERVERNAME____\" value=\"$SERVERNAME\">
<input type=\"hidden\" name=\"____SERVERTYPE____\" value=\"$SERVERTYPE\">
<input type=\"hidden\" name=\"____SERVERMASTER____\" value=\"$SERVERMASTER\">
<input type=\"hidden\" name=\"____CREATETYPE____\" value=\"reuse\">
</form><script>document.frm.submit();</script><form>"
	fi
fi

if [ "$SERVERTYPE" = network ] || [ "$SERVERTYPE" = federated ] && [[ "$SERVERNAME" != $(hostname-fqdn) ]]
then
ssh -x -o PasswordAuthentication=no "$SERVERNAME" '
	#Make sure zfs kernel module is loaded
	modprobe zfs
	#Make sure zfs is going to load on boot and load created pools
	echo "zfs zfs_autoimport_disable=0" > /etc/modules-load.d/zfs.conf

	SORTGLUSTER=no
	if [ -d /home/gluster-volumes/ ] && [ "'"$MOUNTPOINT"'" = /home ]
	then
		SORTGLUSTER=yes
	fi

	function sort_gluster {
	source /opt/karoshi/serversetup/variables/distro
	if [ "$GLUSTERACTION" = stop ]
	then
		echo "<ul><li>'$"Stopping Samba4"'</li></ul>"
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/control_services/samba_stop 1>/dev/null
		echo "<ul><li>'$"Stopping GlusterFS"'</li></ul>"
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/control_services/glusterfs_stop 1>/dev/null
	fi
	if [ "$GLUSTERACTION" = start ]
	then
		echo "<ul><li>'$"Starting GlusterFS"'</li></ul>"
		/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/control_services/glusterfs_start 1>/dev/null
	fi
	for GLUSTERVOL in $(ls /home/gluster-volumes/)
	do
		if [ "$GLUSTERACTION" = stop ]
		then
			#Clear out all of the gluster data
			echo "<ul><li>'$"Glusterfs"' - '$"Removing"' "$GLUSTERVOL" - '$"This will be restored after the ZFS array has been created"'</li></ul>"
			umount /mnt-gluster/"$GLUSTERVOL"
			rm -f -R /home/gluster-volumes/"$GLUSTERVOL"
			mkdir -p /home/gluster-volumes/"$GLUSTERVOL"
		fi		


		if [ "$GLUSTERACTION" = start ]
		then
			(vol="$GLUSTERVOL"; brick=/home/gluster-volumes/"$GLUSTERVOL"; setfattr -n  trusted.glusterfs.volume-id -v 0x$(grep volume-id /var/lib/glusterd/vols/$vol/info | cut -d= -f2 | sed "s/-//g") $brick)
			#Restart the gluster volume
			echo -e "y\n" | gluster volume stop "$GLUSTERVOL" force
			sleep 1
			gluster volume start "$GLUSTERVOL" force
			#Repair the volume with data from the other server.
			gluster volume heal "$GLUSTERVOL" full
			mount -a
		fi			
	done
	if [ "$GLUSTERACTION" = start ]
	then
		#Mount gluster volume and start samba4
		mount -a
		echo "<ul><li>'$"Starting Samba4"'</li></ul>"
		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/control_services/samba_start 1>/dev/null
	fi
	}

	if [ '"$CREATETYPE"' = create ]
	then
		DRIVELIST=$(echo '"$DRIVELIST"' | sed "s/,/ /g")
		#Create the zfs raid
		echo "<pre style=\"font-size: 10pt; font-family:Arial, Times, Georgia, serif\">"

		if [ '"$PARITY"' = stripe ]
		then
			echo "<ul><li>'$"Creating ZFS stripe"'</li></ul>"
		elif [ '"$PARITY"' = mirror ]
		then
			echo "<ul><li>'$"Creating ZFS mirror"'</li></ul>"
		else		
			echo "<ul><li>'$"Creating ZFS raid"' z'"$PARITY"'</li></ul>"
		fi

		#Check that there is not already a pool created for this zfs raid
		if [ `zpool status | grep -c -w '"$POOLNAME"'` -gt 0 ]
		then
			echo '"$POOLNAME"' - $"A ZFS raid has already been set up for this pool.""<br>"
			sleep 3
			exit 101
		fi

		if [ '"$PARITY"' = stripe ]
		then
			zpool create -o ashift=12 -f '"$POOLNAME"' $DRIVELIST
		elif [ '"$PARITY"' = mirror ]
		then
			#Create a zfs mirror
			if [ ! -z "'"$SPAREDRIVELIST"'" ]
			then
				SPAREDRIVELIST=$(echo '"$SPAREDRIVELIST"' | sed "s/,/ /g")
				zpool create -o ashift=12 -f '"$POOLNAME"' mirror $DRIVELIST spare $SPAREDRIVELIST
			else
				zpool create -o ashift=12 -f '"$POOLNAME"' mirror $DRIVELIST
			fi
		else
			if [ ! -z "'"$SPAREDRIVELIST"'" ]
			then
				SPAREDRIVELIST=$(echo '"$SPAREDRIVELIST"' | sed "s/,/ /g")
				zpool create -o ashift=12 -f '"$POOLNAME"' raidz'"$PARITY"' $DRIVELIST spare $SPAREDRIVELIST
			else
				zpool create -o ashift=12 -f '"$POOLNAME"' raidz'"$PARITY"' $DRIVELIST
			fi
		fi

		#Check zfs raid has been created
		zpool status '"$POOLNAME"'
		if [ "$?" != 0 ]
		then
			echo $"A ZFS raid has not been set up on this server.""<br>"
			sleep 3
			exit 101
		fi

		#Set posix acl support
		zfs set acltype=posixacl "'"$POOLNAME"'"

		#Disable dedup as it needs a lot of memory 
		zfs set dedup=off "'"$POOLNAME"'"

		#Mount partition on a temporary mount point
		[ ! -d '"$MOUNTPOINT"'.'"$$"' ] && mkdir -p '"$MOUNTPOINT"'.'"$$"'

		zfs set mountpoint='"$MOUNTPOINT"'.'"$$"' '"$POOLNAME"'
		zfs mount '"$POOLNAME"'

		#Stop services if the mount point is /var
		if [ $(echo '"$MOUNTPOINT"' | grep -c /var) -gt 0 ]
		then
			source /opt/karoshi/serversetup/variables/distro

			SERVICEARRAY=( apache dansguardian mysql samba squid )
			SERVICEARRAYCOUNT="${#SERVICEARRAY[@]}"

			#Stop services if they are running
			COUNTER=0
			while [ "$COUNTER" -lt "$SERVICEARRAYCOUNT" ]
			do
				#Check if the service is running
				/opt/karoshi/serversetup/distro/ubuntu/scripts/control_services/"${SERVICEARRAY[$COUNTER]}"_status
				STATUSARRAY[$COUNTER]="$?"
				#Stop service if it is running
				if [ "${STATUSARRAY[$COUNTER]}" = 0 ]
				then
					echo "<ul><li>${SERVICEARRAY[$COUNTER]} - '$"Stopping this service."'</li></ul>"
					/opt/karoshi/serversetup/distro/ubuntu/scripts/control_services/"${SERVICEARRAY[$COUNTER]}"_stop
				fi
				let COUNTER=$COUNTER+1
			done 
		fi

		#Copy data to new array
		if [ -d '"$MOUNTPOINT"' ]
		then
			if [ "$SORTGLUSTER" = yes ]
			then
				GLUSTERACTION=stop
				sort_gluster
			fi

			echo "<ul><li>'$"Copying existing data onto the raid."'</b></li></ul>"
			sleep 2
			rsync --timeout=30 --verbose --dirs --recursive --links --compress --times --perms --executability --owner --group -o '"$MOUNTPOINT"'/ '"$MOUNTPOINT"'.'"$$"'/

			#Move existing folder and create a new empty folder
			mv '"$MOUNTPOINT"' '"$MOUNTPOINT"'-pre-zfs."$$"
			mkdir '"$MOUNTPOINT"'

		fi

		#Remove any existing partitions from fstab
		if [ `grep -c -w '"$MOUNTPOINT"' /etc/fstab` -gt 0 ]
		then
			#Umount the partition
			echo "<ul><li>'"$MOUNTPOINT"'- '$"Un mounting existing partition"'</li></ul>"
			umount "$MOUNTPOINT"

			#Backup /etc/fstab
			echo "<ul><li>"Backing up fstab"</li></ul>"
			cp /etc/fstab /etc/fstab-backup.'"$$"'

			#Remove entry from fstab
			sed -i "\%'"$MOUNTPOINT"'%d" /etc/fstab
		fi

		#Unmount zfs partition and mount as mountpoint.

		zfs set mountpoint='"$MOUNTPOINT"' '"$POOLNAME"'
		zfs mount '"$POOLNAME"'

		#Remove temporary mount point
		[ -d '"$MOUNTPOINT"'.'"$$"' ] && rm -f -R '"$MOUNTPOINT"'.'"$$"'

		if [ "$SORTGLUSTER" = yes ]
		then
			GLUSTERACTION=start
			sort_gluster
		fi

		echo "</pre>"

		if [ "$POSIXSUPPORT" = no ]
		then
		#Mount partition on boot
			echo "#!/bin/bash
COUNTER=0
while [ "$COUNTER" -le 100 ]
do
	mount /'"$ZPOOLTOPPATH"'/'"$POOLNAME"'/storage '"$MOUNTPOINT"'
	[ \$? = 0 ] && exit
	sleep 1
	let COUNTER=\$COUNTER+1
done" > /etc/rc2.d/S90zfs-mount-'"$POOLNAME"'
			chmod 0700 /etc/rc2.d/S90zfs-mount-'"$POOLNAME"'
		else
			source /opt/karoshi/serversetup/variables/distro
			/opt/karoshi/serversetup/distro/"$DISTROCHOICE"/scripts/startonboot/zfs-mount-all
		fi

		#Start services if they were previously running and were stopped to create a raid on /var
		if [ `echo '"$MOUNTPOINT"' | grep -c /var` -gt 0 ]
		then
			COUNTER=0
			while [ "$COUNTER" -lt "$SERVICEARRAYCOUNT" ]
			do
				if [ ${STATUSARRAY[$COUNTER]} = 0 ]
				then
					echo "<ul><li>${SERVICEARRAY[$COUNTER]} - '$"Starting this service."'</li></ul>"
					/opt/karoshi/serversetup/distro/ubuntu/scripts/control_services/"${SERVICEARRAY[$COUNTER]}"_start
				fi
				let COUNTER=$COUNTER+1
			done
		fi 

	fi

	#Restore existing zfs raid
	if [ '"$CREATETYPE"' = restore ]
	then
		if [ "$SORTGLUSTER" = yes ]
		then
			GLUSTERACTION=stop
			sort_gluster
		fi

		#Move existing folder and create a new empty folder
		if [ -d "'"$MOUNTPOINT"'" ]
		then
			mv '"$MOUNTPOINT"' '"$MOUNTPOINT"'-pre-zfs.'"$$"'
		fi
		mkdir -p '"$MOUNTPOINT"'

		zpool import -f -d /dev/disk/by-id '"$POOLNAME"'

		#Set posix acl support
		zfs set acltype=posixacl "'"$POOLNAME"'"

		#Disable dedup as it needs a lot of memory 
		zfs set dedup=off "'"$POOLNAME"'"

		zfs set mountpoint="'"$MOUNTPOINT"'" "'"$POOLNAME"'"
		zfs mount "'"$POOLNAME"'"

		#Copy any existing data back onto the raid
		if [ -d '"$MOUNTPOINT"'-pre-zfs.'"$$"' ]
		then
			echo "<pre style=\"font-size: 10pt; font-family:Arial, Times, Georgia, serif\">"
			rsync --timeout=30 --verbose --dirs --recursive --links --compress --times --perms --acls --executability --owner --group -o '"$MOUNTPOINT"'-pre-zfs.'"$$"'/ '"$MOUNTPOINT"'/
			echo "</pre>"
		fi

		if [ "$SORTGLUSTER" = yes ]
		then
			GLUSTERACTION=start
			sort_gluster
		fi

		source /opt/karoshi/serversetup/variables/distro
		/opt/karoshi/serversetup/distro/$DISTROCHOICE/scripts/startonboot/zfs-mount-all

	fi

	#Reuse existing zfs raid
	if [ '"$CREATETYPE"' = reuse ]
	then
		echo "</form><form METHOD=POST ACTION=\"/cgi-bin/admin/zfs_raid_create.cgi\" target=\"_top\" name = \"frm\">
<input type=\"hidden\" name=\"____SERVERNAME____\" value=\"'"$SERVERNAME"'\">
<input type=\"hidden\" name=\"____SERVERTYPE____\" value=\"'"$SERVERTYPE"'\">
<input type=\"hidden\" name=\"____SERVERMASTER____\" value=\"'"$SERVERMASTER"'\">
<input type=\"hidden\" name=\"____CREATETYPE____\" value=\"reuse\">
</form><script>document.frm.submit();</script><form>"
	fi

	#Add cron job for zpool scrub
	[ -d /opt/karoshi/server_network/cronjobs/'"$SERVERNAME"'/jobs ] || mkdir -p /opt/karoshi/server_network/cronjobs/'"$SERVERNAME"'/jobs
	echo 0 0 "*" "*" 6 zpool scrub '"$POOLNAME"' > /opt/karoshi/server_network/cronjobs/'"$SERVERNAME"'/jobs/zpool_scrub_'"$POOLNAME"'.cron
	/opt/karoshi/serversetup/all/"useful scripts"/refreshcronjobs
	echo "<br>"
'
fi

if [ "$SERVERTYPE" = federatedslave ]
then
ssh -o PasswordAuthentication=no -o ConnectTimeout=3 "$SERVERMASTER" '
echo `date`: zfs_raid_create2 \(federated mode\) - servername '"$SERVERNAME"' servertype '"$SERVERTYPE"' raidtype '"$RAIDTYPE"' drivelist '"$DRIVELIST"' mountpoint '"$MOUNTPOINT"' by '"$REMOTE_USER"' from '"$REMOTE_ADDR"' >> /opt/karoshi/logs/karoshi_web_management/'"$LOG_DATE"'
ssh -o PasswordAuthentication=no -o ConnectTimeout=3 '"$SERVERNAME"' '\''

echo in ssh2
'\''
'
fi

exit

